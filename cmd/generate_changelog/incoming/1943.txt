### PR [#1943](https://github.com/danielmiessler/Fabric/pull/1943) by [ksylvan](https://github.com/ksylvan): fix: Ollama server now respects the default context window

- Fix: Ollama server now respects the default context window instead of using hardcoded 2048 tokens
- Add parseOllamaNumCtx() function with type-safe extraction supporting 6 numeric types and platform-aware integer overflow protection
- Extract num_ctx from client request options and add ModelContextLength field to ChatRequest struct
- Implement DoS protection via 1,000,000 token maximum limit with sanitized error messages
- Add comprehensive unit tests for parseOllamaNumCtx function covering edge cases including overflow and invalid types
